#
# Copyright (C) 2014 Stratio (http://stratio.com)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#         http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#Print streams in each spark iteration
printStreams = false

#Enable stats
statsEnabled = false

#Save all actions realized on the platform
auditEnabled = false

// Clustering configuration. From this section is possible to configure the High Availability and Sharding capabilities
clustering = {

	// Is the clustering enabled? If true, one of the Decision instances which belongs to the same clusterId will be on charge of manage the cluster status and sync operations
	enabled = false

	// The name of the group. A group is composed by the number of Decision instances configured in the same way in order to offer HA capabilities. To the same group can belongs 1 (not HA) or 2 (HA) Decision instances.
	groupId = "default"

	partitionsEnabled = false

	// List of groups which belongs to the same cluster. It should be the same list in all nodes of the cluster.
	#clusterGroups = ["groupA", "groupB"]

	// List of Kafka topics subscribed by this Decisision instance
	#dataTopics = ["topic_A"]

	// Is failover enabled? It have to be true if you need HA capabilities
	failoverEnabled = false

	failoverPeriod = 300s

	allAckEnabled= false

	ackTimeout = 500 //ms
}

kafka = {
	hosts = ["localhost:9092"]
	connectionTimeout = 10000
	sessionTimeout = 10000
	zookeeperPath = ""

	# default replication factor and partitions for internal topics
	replicationFactor = 1
	partitions = 1
}

zookeeper = {
	hosts = ["localhost:2181"]
}
spark = {
	internalHost = "local[6]"
	internalStreamingBatchTime = 2 s

	host ="local[6]"
	streamingBatchTime = 2 s
}

cassandra = {
	hosts = ["localhost:9042"]
	maxBatchSize = 50
	batchType = "UNLOGGED"
}

mongo = {
	hosts = ["localhost:27017"]
	#username = ""
	#password= ""
	maxBatchSize = 500
}

elasticsearch = {
	hosts = ["localhost:9300"]
	clusterName = "elasticsearch"
	maxBatchSize = 1000
}

solr = {
	hosts = "localhost:2181"
	cloud = true
	dataDir = "/opt/sds/solr/examples/solr"
}


