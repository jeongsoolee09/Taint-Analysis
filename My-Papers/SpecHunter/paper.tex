%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
% \documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
% \documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
% \documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
% \documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
% \setcopyright{acmcopyright}
% \setcopyright{acmlicensed}
% \setcopyright{rightsretained}
% \copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
%% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption


\begin{document}

%% Title information
\title{SpecHunter: Interactively Inferring Taint Specifications Using Bayes Net}        
%% when present, will be used in
%% header instead of Full Title.
\titlenote{with title note}             %% \titlenote is optional;
%% can be repeated if necessary;
%% contents suppressed with 'anonymous'
\subtitle{Subtitle}                     %% \subtitle is optional
\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
%% can be repeated if necessary;
%% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
% \author{First2 Last2}
% \authornote{with author2 note}          %% \authornote is optional;
%                                         %% can be repeated if necessary
% \orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
% \affiliation{
% \position{Position2a}
% \department{Department2a}             %% \department is recommended
% \institution{Institution2a}           %% \institution is required
% \streetaddress{Street2a Address2a}
% \city{City2a}
% \state{State2a}
% \postcode{Post-Code2a}
% \country{Country2a}                   %% \country is recommended
% }
%   \email{first2.last2@inst2a.com}         %% \email is recommended
%   \affiliation{
%   \position{Position2b}
%   \department{Department2b}             %% \department is recommended
%   \institution{Institution2b}           %% \institution is required
%   \streetaddress{Street3b Address2b}
%   \city{City2b}
%   \state{State2b}
%   \postcode{Post-Code2b}
%   \country{Country2b}                   %% \country is recommended
% }
%   \email{first2.last2@inst2b.org}         %% \email is recommended


%%   Abstract
%%   Note: \begin{abstract}...\end{abstract} environment must come
%%   before \maketitle command
\begin{abstract}
  % Taint analysis becomes a must for Java projects where foreign codes such as
  % external frameworks are frequently used in building them.
  % % Taint specification 추론이 왜 필요한지
  % For accurate taint analysis, the analyzer must first be told which methods are
  % sources, sinks, sanitizers, or none of them. However, Manually determining such
  % labels for every method used or defined in a project is a tedious task that
  % becomes nearly impossible if the codebase becomes large.
  % % 그러므로 우리의 아이디어를 제시한다
  % To alleviate such burden, we present Spechunter which, given a small
  % portion of the entire methods which are not deadcodes, finds out taint specifications
  % of the rest of the methods in a Java project built with frameworks.
  % % 우리 아이디어의 특징
  % Spechunter's uniqueness lies in its efficiency, achieved by only
  % drawing minimum manpower necessary for doing its job. This is possible due to its
  % interactive nature: it ends an ongoing interaction as soon as it determines that enough
  % evidence is obtained from the oracle. To achieve this, Spechunter relies on
  % building Bayesian networks and performing marginal inference on it given accumulating
  % evidence. Our experiments show that ...

  % 위의 버전은 영양가도 없으면서 너무 장황하다. Lets give it a full rewrite!

  SpecHunter is a tool for inferring taint specifications, aiming to serve any
  Java taint analyzers, enabling them to be more precise in finding out data
  flows from a source method to a sink method, without passing through a
  sanitizer. By asking questions to an external oracle on selected APIs used in
  a given Java application, it can acheive the following two goals. First,
  SpecHunter is language-agnostic, since it only focuses on the Java application at
  hand, and ignores whether or not the used APIs are implemented in languages
  other than Java. Therefore, it can be used for any Java application, regardless
  of what libraries or frameworks they use. Second, SpecHunter is
  efficient, because the APIs necessary for efficient propagation is automatically selected
  by SpecHunter itself. This allows the user to skip all trial-and-error in
  configurating the training set for a learning model, as required by previous
  machine learning approaches. Results of our experiments show that SpecHunter
  actually delivers the aforementioned promises, by running on applications with
  Scala and C++ libraries, with only questions asked to the user.  
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10011007.10011006.10011008</concept_id>
  <concept_desc>Software and its engineering~General programming languages</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003456.10003457.10003521.10003525</concept_id>
  <concept_desc>Social and professional topics~History of programming languages</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}
% A large portion of Java projects are built using frameworks such as Spring,
% Hibernate, or Android. These frameworks are foreign codes, so importing their
% APIs may introduce new security vulnerabilities. Finding out such security holes
% requires running taint analysis, which looks for a data flow starting from a
% source method to a sink method without passing through a sanitizer method.
% However, taint analyzers should be correctly told which method is a source,
% sink, sanitizer, or none of them at the first place, otherwise it may result in
% false negatives or false positives. However, manually labelling all methods used
% or defined in a project with the above four labels is a laborous task to be
% manually done, and becomes nearly impossible to do so if the codebase gets
% larger. Therefore, there have been previous works to lessen this burden.

% 2021-02-15 16:44:59에 다시 쓴 버전:

Taint analysis, whether static or dynamic, aims to find security vulnerabilities lurking
in the given program. These vulnerabilities include SQL injection, cross-site
scripting, and abused printf-arguments. They are typically formulated as a
data flow starting from a `source' method to a `sink' method, without the
flowing data being `sanitized' by an appropriate method. For such search to be
precise enough, the analyzer must first be told which methods are sources,
sinks, sanitizers, or none of them. However, going through the codebase
searching for imported APIs and labelling every one of them by hand becomes too
time-consuming as the codebase gets larger.

% TODO BibTeX을 쓸 줄 모르므로 일단 툴 이름으로 Reference로의 링크를 대신함
% Boldface들을 BibTeX으로 바꿀 것.
To aid such manpower, previous studies proposed methods such as supervised
learning (\textbf{SuSI}, \textbf{SWAN}), and semi-supervised learning (\textbf{Seldon}, \textbf{Merlin}).
However, works belonging to each camp suffers from their own limitations.

\paragraph{Shortcomings of Supervised Learning Camp.}

\textbf{SuSI} and \textbf{SWAN} both work in a similar way: they first train a learning model
such as a support vector machine with the actual library codes implementing
APIs. Here, the function bodies are interprocedurally analyzed with a Java
static analyzer to get the vectors of feature values. Then, they take a whole
library codebase into the pre-trained learning
model, and get the mapping from all APIs in the library to their respective
specifications. While they work nice against libraries written in pure Java
code such as Spring, they cannot work if a given application imports libraries
written in other languages other than Java. This is because in order to extract
the feature values they would have to be equipped with all the possible
languages the libraries would be in, and this is practically difficult.

% TODO: add an additional shortcoming: features should also be updated if a new
% library is provided

\paragraph{Shortcomings of Semi-Supervised Learning Camp.}

As a workaround to the above limitation, one can try a semi-supervised learning
approach. The state-of-the-art belonging to this camp is \textbf{Seldon}.
\textbf{Seldon} only takes the application code into consideration, thus it does
not care which language the library is written in. So, for example, Seldon can
figure out the label of an API function in a Python program, which is
actually implemented in C++. However, Seldon suffers from a common problem of
all machine-learning solutions, that it is largely dependent on quality dataset.
In fact, the authors reports that \textbf{Seldon}'s precision dropped by 14
percent-points by just providing half of the original specifications. Moreover,
this problem is shared with supervised learning solutions, those are also
data-driven solutions.
% Seldon 논문의 부분을 인용하고 싶은데... 형식을 모르겠네
% 해당 부분:
% Q6: Impact of Seed Specification. We also evaluated Sel-
% don’s precision for half the seed specification (considering
% only odd line numbers in App. B). This significantly reduces
% precision, by 14 percentage-points. Thus, we believe our
% seed specification strikes a good balance between manual
% effort and precision. We note that in the extreme case of an
% empty seed specification, Seldon will predict 0 specifications,
% because picking 0 for all variables is a trivial solution to its
% constraint system.

\paragraph{Our Tool: Real-Time Interactive Inference.}

Our tool, SpecHunter, works in a different manner than data-driven
approaches. Instead of training the model with some predetermined pairs of
methods and their labels to predict other methods' labels, we analyze the given
application to construct probabilistic graphical models of a certain type,
called Bayesian networks. They are special in that they provide a model of
conditional-probabilistic reasoning, which infers the marginal probabilities of
each random variables when some of them are instantiated to a certain value by
an external source. Therefore, we determine a structure of a Bayesian network by
running a static analysis on the given application code, and make the system ask
the user, the external entity, for evidence. Then, SpecHunter picks the most
influential node which has the most other nodes that depend upon it. This makes
the interaction session both effective and efficient.

The experiments show that ...   % TODO

\paragraph{Contributions.}

- We provide SpecHunter
- We provide src/sin/san/non ground truths
- We provide a taint analyzer (is it possible?)
- We make the tool open source (is it possible?)

\section{Overview}

\paragraph{Motivation}

Swan sucks: too much variance on its performance

\paragraph{Overview of our System}


\paragraph{Static Analysis}


\paragraph{Constructing Bayesian Networks}


\section{Evaluation}

\paragraph{Discussions}

\paragraph{Limitations}


\section{Related Work}


\section{Conclusion}


%% Acknowledgments
\begin{acks}                            %% acks environment is optional
  %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}. Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
% \bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
