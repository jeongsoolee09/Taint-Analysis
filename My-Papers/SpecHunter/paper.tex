%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[sigconf,review,anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
% \documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
% \documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
% \documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
% \documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2018}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
% \setcopyright{acmcopyright}
% \setcopyright{acmlicensed}
% \setcopyright{rightsretained}
% \copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
%% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
%% http://ctan.org/pkg/subcaption

\usepackage{listing}

\begin{document}

%% Title information
\title{SpecHunter: Interactively Inferring Taint Specifications Using Bayes Net}        
%% when present, will be used in
%% header instead of Full Title.
\titlenote{with title note}             %% \titlenote is optional;
%% can be repeated if necessary;
%% contents suppressed with 'anonymous'
\subtitle{Subtitle}                     %% \subtitle is optional
\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
%% can be repeated if necessary;
%% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
% \author{First2 Last2}
% \authornote{with author2 note}          %% \authornote is optional;
%                                         %% can be repeated if necessary
% \orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
% \affiliation{
% \position{Position2a}
% \department{Department2a}             %% \department is recommended
% \institution{Institution2a}           %% \institution is required
% \streetaddress{Street2a Address2a}
% \city{City2a}
% \state{State2a}
% \postcode{Post-Code2a}
% \country{Country2a}                   %% \country is recommended
% }
%   \email{first2.last2@inst2a.com}         %% \email is recommended
%   \affiliation{
%   \position{Position2b}
%   \department{Department2b}             %% \department is recommended
%   \institution{Institution2b}           %% \institution is required
%   \streetaddress{Street3b Address2b}
%   \city{City2b}
%   \state{State2b}
%   \postcode{Post-Code2b}
%   \country{Country2b}                   %% \country is recommended
% }
%   \email{first2.last2@inst2b.org}         %% \email is recommended


%%   Abstract
%%   Note: \begin{abstract}...\end{abstract} environment must come
%%   before \maketitle command
\begin{abstract}
  SpecHunter is a tool for inferring taint specifications, aiming to aid anyone
  trying to use a Java taint analyzer, but being overwhelmed by the number of APIs that
  should be marked of their specifications to run it. SpecHunter aims to lessen this burden
  by constructing a Bayesian network and performing live interaction with the user, in which
  it systematically picks a method and asks the user of its specification. By taking an
  interactive approach, SpecHunter can run on Java applications that use libraries that are
  implemented in languages other than Java. Also, SpecHunter skips all trial-and-errors
  in configurating the data-set required in using any of the traditional machine-learning approaches.
  Our experiments show that SpecHunter actually delivers those promises.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10011007.10011006.10011008</concept_id>
  <concept_desc>Software and its engineering~General programming languages</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003456.10003457.10003521.10003525</concept_id>
  <concept_desc>Social and professional topics~History of programming languages</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Introduction}
Taint analysis, whether static or dynamic, aims to find security vulnerabilities lurking
in the given program. These vulnerabilities include SQL injection, cross-site
scripting, and abused printf-arguments. They are typically formulated as a
data flow starting from a `source' method to a `sink' method, without the
flowing data being `sanitized' by a relevant method. For such search to be
precise enough, the analyzer must first be told which methods are sources,
sinks, sanitizers, or none of them. However, going through the codebase
searching for imported APIs and labelling every one of them by hand quickly becomes tedious
thing to do as the codebase gets larger.

% TODO BibTeX을 쓸 줄 모르므로 일단 툴 이름으로 Reference로의 링크를 대신함
% Boldface들을 BibTeX으로 바꿀 것.
To aid such manpower, previous studies proposed methods such as supervised
learning (\textbf{SuSI}, \textbf{SWAN}), and semi-supervised learning (\textbf{Seldon}, \textbf{Merlin}).
However, works belonging to each camp suffers from their own limitations.

\paragraph{Shortcomings of Supervised Learning Camp.}

\textbf{SuSI} and \textbf{SWAN} both work in a similar way: they first train a learning model
such as a support vector machine with the actual library codes implementing
APIs. Here, the function bodies are interprocedurally analyzed with a Java
static analyzer to get the vectors of feature values. Then, they take a whole
library codebase into the pre-trained learning
model, and get the mapping from all APIs in the library to their respective
specifications. While they work nicely against libraries written in pure Java
code such as Spring, they cannot work if a given application imports libraries
written in other languages other than Java. This is because in order to extract
the feature values they would have to be equipped with all the possible
languages the libraries would be in, and this is practically difficult.

% TODO: add an additional shortcoming: features should also be updated if a new
% library is provided

\paragraph{Shortcomings of Semi-Supervised Learning Camp.}

As a workaround to the above limitation, one can try a semi-supervised learning
approach. The state-of-the-art belonging to this camp is \textbf{Seldon}.
\textbf{Seldon} only takes the application code into consideration, thus it does
not care which language the library is written in. So, for example, Seldon can
figure out the label of an API function in a Python program, which is
actually implemented in C++. However, Seldon suffers from a common problem of
all machine-learning solutions, that it is largely dependent on quality dataset.
In fact, the authors reports that \textbf{Seldon}'s precision dropped by 14
percent-points by just providing half of the original specifications. Moreover,
this problem is shared with supervised learning solutions, those are also
data-driven solutions.
% Seldon 논문의 부분을 인용하고 싶은데... 형식을 모르겠네
% 해당 부분:
% Q6: Impact of Seed Specification. We also evaluated Sel-
% don’s precision for half the seed specification (considering
% only odd line numbers in App. B). This significantly reduces
% precision, by 14 percentage-points. Thus, we believe our
% seed specification strikes a good balance between manual
% effort and precision. We note that in the extreme case of an
% empty seed specification, Seldon will predict 0 specifications,
% because picking 0 for all variables is a trivial solution to its
% constraint system.

\paragraph{Our Tool: Real-Time Interactive Inference.}

Our tool, SpecHunter, works in a different manner than data-driven
approaches. Instead of training the model with some predetermined pairs of
methods and their labels to predict other methods' labels, we analyze the given
application to construct probabilistic graphical models of a certain type,
called Bayesian networks. They are special in that they provide a model of
conditional-probabilistic reasoning, which infers the marginal probabilities of
each random variables when some of them are instantiated to a certain value by
an external source. Therefore, we first determine a structure of a Bayesian network
by running a static analysis on the given application code, and make the system ask
the user, the external entity, for evidence. Then, SpecHunter picks the most
influential node which has the most dependent nodes. This makes the interaction
session both effective and efficient.

The experiments show that SpecHunter effectively infers taint specifications for
methods that are untold of its label, with \textbf{xx}\% precision when told only
\textbf{17.7}\% of all APIs.


\paragraph{Contributions.}

\begin{itemize}
  \item We provide SpecHunter
  \item We provide src/sin/san/non ground truths
  \item We provide a taint analyzer (is it possible?)
  \item We make the tool open source (is it possible?)
\end{itemize}

\section{Overview}

\paragraph{Motivation}

Swan sucks: too much variance on its performance depending on dataset quality/quantity

\subsection{Overview of our System}

% 적당한 figure 하나 넣자

Figure 1 shows the overall workflow of SpecHunter. Given a Java application's
source code, SpecHunter labels all API methods provided by the library the application
uses. There are three main issues regarding building an effective interactive system:
namely, constructing the network, effectively propagating the evidence given from the
oracle, and making the system scale to run on large input applications.
% Question: Should we define what "API" means?

\subsection{Network Construction}

% Network Construction은 반드시 Scalability and Efficiency와 연관되게 되어 있다.
% 그 점을 유념하면서 쓰자: 적절한 pointer 달아 주기.
Here we describe how we represent the input java project into a graph form, which will
later be turned into a series of Bayesian networks. We hope to create a graph G=(V, E),
where V is the set of all methods used or defined in the given application, and E is a
subset of V * V, whose elements are gathered in three different ways.

First, there are data-flow-edges. We perform a variant of a data-flow analysis on the
given input application to calculate lifetimes of all access paths found in the entire code.
% 여기서 간단한 예제 넣어주기

\begin{figure}[t]
  \begin{lstlisting}

    public int m1() {
      return 1;
    }

    public int m2(int u1) {
      return ++u1;
    }

    public void m3(int u2) {
      System.out.println(u2);
    }

    public void f() {
      int x = m1();
      g(x);
    }

    public void g(int y) {
      int z = m2(y);
      h(z);
    }

    public void h(int w) {
      m3(w);
    }
    
  \end{lstlisting}
\caption{Example Java program with a data flow.}
vspace{-0.6em}
\label{fig:sca}
\end{figure}




Second, there are call-edges.

Last but not least, there are similarity-edges.


\subsection{Graph Splitting}



\subsection{Information Propagation}


\section{Evaluation}

\subsection{RQs}
\begin{itemize}
  \item How effective is SH in finding src/sin/san?  % I am really really worried about this
  \item How efficient is SH?
  \item Interaction user-study % possible?
\end{itemize}

% why is this meaningful? (with/without comparison)
% at least mention comparison

\paragraph{Discussions}
How well are propagations working? (Quant, Qualit) .
How stable is SpecHunter over multiple iterations?
\paragraph{Limitations}

\paragraph{Threats to Validity.}


\section{Related Work}


\section{Conclusion}


%% Acknowledgments
\begin{acks}                            %% acks environment is optional
  %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}. Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}


%% Bibliography
% \bibliography{bibfile}


%% Appendix
\appendix
\section{Appendix}

Text of appendix \ldots

\end{document}
